{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Twitter_Sentiment_Analysis_Ensemble.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"code","metadata":{"id":"78PhOL0jpZdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855638391,"user_tz":360,"elapsed":27053,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"20a03d96-ed18-4634-d674-5aede2668e4f"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AEM1ZS6vpu6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855638393,"user_tz":360,"elapsed":26470,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"e4bf5fe2-1c7c-49a8-c3bf-b84668821ebc"},"source":["%cd /content/drive/My Drive/Research Project"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Research Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h0jpgwEQU_Av","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855645093,"user_tz":360,"elapsed":6941,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"0c593788-3157-438f-c437-6255e26355e8"},"source":["pip install --upgrade transformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting transformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/2c/4e/4f1ede0fd7a36278844a277f8d53c21f88f37f3754abf76a5d6224f76d4a/transformers-3.4.0-py3-none-any.whl (1.3MB)\n","\u001b[K     |████████████████████████████████| 1.3MB 4.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n","Requirement already satisfied, skipping upgrade: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n","Collecting tokenizers==0.9.2\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7c/a5/78be1a55b2ac8d6a956f0a211d372726e2b1dd2666bb537fea9b03abd62c/tokenizers-0.9.2-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n","\u001b[K     |████████████████████████████████| 2.9MB 14.2MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n","Requirement already satisfied, skipping upgrade: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n","Requirement already satisfied, skipping upgrade: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n","Collecting sacremoses\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n","\u001b[K     |████████████████████████████████| 890kB 44.9MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n","Collecting sentencepiece!=0.1.92\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/e5/2d/6d4ca4bef9a67070fa1cac508606328329152b1df10bdf31fb6e4e727894/sentencepiece-0.1.94-cp36-cp36m-manylinux2014_x86_64.whl (1.1MB)\n","\u001b[K     |████████████████████████████████| 1.1MB 35.4MB/s \n","\u001b[?25hRequirement already satisfied, skipping upgrade: protobuf in /usr/local/lib/python3.6/dist-packages (from transformers) (3.12.4)\n","Requirement already satisfied, skipping upgrade: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n","Requirement already satisfied, skipping upgrade: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n","Requirement already satisfied, skipping upgrade: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.10)\n","Requirement already satisfied, skipping upgrade: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n","Requirement already satisfied, skipping upgrade: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n","Requirement already satisfied, skipping upgrade: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.15.0)\n","Requirement already satisfied, skipping upgrade: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n","Requirement already satisfied, skipping upgrade: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.17.0)\n","Requirement already satisfied, skipping upgrade: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf->transformers) (50.3.2)\n","Building wheels for collected packages: sacremoses\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893257 sha256=261687232e2cc14f339091622f617865c059c544dd7cd0eecb038ad7b78e8c07\n","  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n","Successfully built sacremoses\n","Installing collected packages: tokenizers, sacremoses, sentencepiece, transformers\n","Successfully installed sacremoses-0.0.43 sentencepiece-0.1.94 tokenizers-0.9.2 transformers-3.4.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"jvEqRZL_Udz7","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"ok","timestamp":1604855674299,"user_tz":360,"elapsed":35807,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"b90de932-0e63-466c-bd43-0245e81ef09e"},"source":["pip install simpletransformers"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting simpletransformers\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/f8/e1dc33cf9b213cd615d940fa20eda295004f32ce86312992e692dabb9b9e/simpletransformers-0.48.15-py3-none-any.whl (215kB)\n","\u001b[K     |████████████████████████████████| 225kB 5.3MB/s \n","\u001b[?25hCollecting wandb\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b6/bc2727589a445e5f5fe03a6fb69db66e7175c26021cc581929fbe3f56248/wandb-0.10.9-py2.py3-none-any.whl (1.8MB)\n","\u001b[K     |████████████████████████████████| 1.8MB 14.6MB/s \n","\u001b[?25hRequirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2.23.0)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.18.5)\n","Requirement already satisfied: regex in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (2019.12.20)\n","Requirement already satisfied: transformers>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (3.4.0)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.4.1)\n","Collecting seqeval\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9d/2d/233c79d5b4e5ab1dbf111242299153f3caddddbb691219f363ad55ce783d/seqeval-1.2.2.tar.gz (43kB)\n","\u001b[K     |████████████████████████████████| 51kB 8.5MB/s \n","\u001b[?25hRequirement already satisfied: pandas in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (1.1.4)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.22.2.post1)\n","Requirement already satisfied: tokenizers in /usr/local/lib/python3.6/dist-packages (from simpletransformers) (0.9.2)\n","Collecting streamlit\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/64/59c5a06d567d27fda54a00db3789a05b50a4dd532df9260cadcff8dd4be9/streamlit-0.70.0-py2.py3-none-any.whl (7.4MB)\n","\u001b[K     |████████████████████████████████| 7.4MB 37.1MB/s \n","\u001b[?25hCollecting tqdm>=4.47.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/93/3a/96b3dc293aa72443cf9627444c3c221a7ba34bb622e4d8bf1b5d4f2d9d08/tqdm-4.51.0-py2.py3-none-any.whl (70kB)\n","\u001b[K     |████████████████████████████████| 71kB 9.9MB/s \n","\u001b[?25hCollecting tensorboardx\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/af/0c/4f41bcd45db376e6fe5c619c01100e9b7531c55791b7244815bac6eac32c/tensorboardX-2.1-py2.py3-none-any.whl (308kB)\n","\u001b[K     |████████████████████████████████| 317kB 52.6MB/s \n","\u001b[?25hCollecting subprocess32>=3.5.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/32/c8/564be4d12629b912ea431f1a50eb8b3b9d00f1a0b1ceff17f266be190007/subprocess32-3.5.4.tar.gz (97kB)\n","\u001b[K     |████████████████████████████████| 102kB 14.8MB/s \n","\u001b[?25hCollecting GitPython>=1.0.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/24/d1/a7f8fe3df258549b303415157328bfcc63e9b11d06a7ad7a3327f3d32606/GitPython-3.1.11-py3-none-any.whl (159kB)\n","\u001b[K     |████████████████████████████████| 163kB 50.9MB/s \n","\u001b[?25hCollecting sentry-sdk>=0.4.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/86/36/afa3c32f61cb62bef0da7200651d41f36b8b069d9f6254d8df8a20b224b8/sentry_sdk-0.19.2-py2.py3-none-any.whl (127kB)\n","\u001b[K     |████████████████████████████████| 133kB 55.7MB/s \n","\u001b[?25hRequirement already satisfied: python-dateutil>=2.6.1 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (2.8.1)\n","Collecting watchdog>=0.8.3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/0e/06/121302598a4fc01aca942d937f4a2c33430b7181137b35758913a8db10ad/watchdog-0.10.3.tar.gz (94kB)\n","\u001b[K     |████████████████████████████████| 102kB 15.3MB/s \n","\u001b[?25hRequirement already satisfied: Click>=7.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (7.1.2)\n","Collecting shortuuid>=0.5.0\n","  Downloading https://files.pythonhosted.org/packages/25/a6/2ecc1daa6a304e7f1b216f0896b26156b78e7c38e1211e9b798b4716c53d/shortuuid-1.0.1-py3-none-any.whl\n","Requirement already satisfied: protobuf>=3.12.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (3.12.4)\n","Collecting configparser>=3.8.1\n","  Downloading https://files.pythonhosted.org/packages/08/b2/ef713e0e67f6e7ec7d59aea3ee78d05b39c15930057e724cc6d362a8c3bb/configparser-5.0.1-py3-none-any.whl\n","Requirement already satisfied: promise<3,>=2.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (2.3)\n","Requirement already satisfied: six>=1.13.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (1.15.0)\n","Collecting docker-pycreds>=0.4.0\n","  Downloading https://files.pythonhosted.org/packages/f5/e8/f6bd1eee09314e7e6dee49cbe2c5e22314ccdb38db16c9fc72d2fa80d054/docker_pycreds-0.4.0-py2.py3-none-any.whl\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (3.13)\n","Requirement already satisfied: psutil>=5.0.0 in /usr/local/lib/python3.6/dist-packages (from wandb->simpletransformers) (5.4.8)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2020.6.20)\n","Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (2.10)\n","Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (3.0.4)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->simpletransformers) (1.24.3)\n","Requirement already satisfied: sentencepiece!=0.1.92 in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.1.94)\n","Requirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.7)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (3.0.12)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (0.0.43)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers>=3.0.2->simpletransformers) (20.4)\n","Requirement already satisfied: pytz>=2017.2 in /usr/local/lib/python3.6/dist-packages (from pandas->simpletransformers) (2018.9)\n","Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->simpletransformers) (0.17.0)\n","Requirement already satisfied: tornado>=5.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (5.1.1)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (1.5.1)\n","Collecting botocore>=1.13.44\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/99/40/b5e681d80dc46bafd0dc2e55266190cc432dfd5b72b9e7e1c5743aa6c362/botocore-1.19.13-py2.py3-none-any.whl (6.7MB)\n","\u001b[K     |████████████████████████████████| 6.7MB 46.2MB/s \n","\u001b[?25hRequirement already satisfied: astor in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (0.8.1)\n","Collecting boto3\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/85/54/099a2ea5d4b2d5931a26f280a7585f613b1fafaac9189e489a9e25004a01/boto3-1.16.13-py2.py3-none-any.whl (129kB)\n","\u001b[K     |████████████████████████████████| 133kB 52.6MB/s \n","\u001b[?25hCollecting enum-compat\n","  Downloading https://files.pythonhosted.org/packages/55/ae/467bc4509246283bb59746e21a1a2f5a8aecbef56b1fa6eaca78cd438c8b/enum_compat-0.0.3-py3-none-any.whl\n","Requirement already satisfied: toml in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (0.10.2)\n","Requirement already satisfied: cachetools>=4.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (4.1.1)\n","Requirement already satisfied: pyarrow in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (0.14.1)\n","Collecting validators\n","  Downloading https://files.pythonhosted.org/packages/41/4a/3360ff3cf2b4a1b9721ac1fbff5f84663f41047d9874b3aa1ac82e862c44/validators-0.18.1-py3-none-any.whl\n","Collecting pydeck>=0.1.dev5\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9e/9d/8fbf1f56cc5891e6c3295bf94fc176e9ab0a3ffdd090cc8b354ac2640f9a/pydeck-0.5.0-py2.py3-none-any.whl (4.5MB)\n","\u001b[K     |████████████████████████████████| 4.5MB 50.5MB/s \n","\u001b[?25hRequirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (7.0.0)\n","Collecting blinker\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/1b/51/e2a9f3b757eb802f61dc1f2b09c8c99f6eb01cf06416c0671253536517b6/blinker-1.4.tar.gz (111kB)\n","\u001b[K     |████████████████████████████████| 112kB 50.8MB/s \n","\u001b[?25hRequirement already satisfied: altair>=3.2.0 in /usr/local/lib/python3.6/dist-packages (from streamlit->simpletransformers) (4.1.0)\n","Collecting base58\n","  Downloading https://files.pythonhosted.org/packages/3c/03/58572025c77b9e6027155b272a1b96298e711cd4f95c24967f7137ab0c4b/base58-2.0.1-py3-none-any.whl\n","Collecting gitdb<5,>=4.0.1\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/11/d1800bca0a3bae820b84b7d813ad1eff15a48a64caea9c823fc8c1b119e8/gitdb-4.0.5-py3-none-any.whl (63kB)\n","\u001b[K     |████████████████████████████████| 71kB 10.6MB/s \n","\u001b[?25hCollecting pathtools>=0.1.1\n","  Downloading https://files.pythonhosted.org/packages/e7/7f/470d6fcdf23f9f3518f6b0b76be9df16dcc8630ad409947f8be2eb0ed13a/pathtools-0.1.2.tar.gz\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.12.0->wandb->simpletransformers) (50.3.2)\n","Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers>=3.0.2->simpletransformers) (2.4.7)\n","Collecting jmespath<1.0.0,>=0.7.1\n","  Downloading https://files.pythonhosted.org/packages/07/cb/5f001272b6faeb23c1c9e0acc04d48eaaf5c862c17709d20e3469c6e0139/jmespath-0.10.0-py2.py3-none-any.whl\n","Collecting s3transfer<0.4.0,>=0.3.0\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/69/79/e6afb3d8b0b4e96cefbdc690f741d7dd24547ff1f94240c997a26fa908d3/s3transfer-0.3.3-py2.py3-none-any.whl (69kB)\n","\u001b[K     |████████████████████████████████| 71kB 2.9MB/s \n","\u001b[?25hRequirement already satisfied: decorator>=3.4.0 in /usr/local/lib/python3.6/dist-packages (from validators->streamlit->simpletransformers) (4.4.2)\n","Requirement already satisfied: traitlets>=4.3.2 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (4.3.3)\n","Requirement already satisfied: jinja2>=2.10.1 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (2.11.2)\n","Requirement already satisfied: ipywidgets>=7.0.0 in /usr/local/lib/python3.6/dist-packages (from pydeck>=0.1.dev5->streamlit->simpletransformers) (7.5.1)\n","Collecting ipykernel>=5.1.2; python_version >= \"3.4\"\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/52/19/c2812690d8b340987eecd2cbc18549b1d130b94c5d97fcbe49f5f8710edf/ipykernel-5.3.4-py3-none-any.whl (120kB)\n","\u001b[K     |████████████████████████████████| 122kB 56.2MB/s \n","\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.3)\n","Requirement already satisfied: toolz in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (0.11.1)\n","Requirement already satisfied: jsonschema in /usr/local/lib/python3.6/dist-packages (from altair>=3.2.0->streamlit->simpletransformers) (2.6.0)\n","Collecting smmap<4,>=3.0.1\n","  Downloading https://files.pythonhosted.org/packages/b0/9a/4d409a6234eb940e6a78dfdfc66156e7522262f5f2fecca07dc55915952d/smmap-3.0.4-py2.py3-none-any.whl\n","Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.6/dist-packages (from traitlets>=4.3.2->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.0)\n","Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.6/dist-packages (from jinja2>=2.10.1->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.1.1)\n","Requirement already satisfied: ipython>=4.0.0; python_version >= \"3.3\" in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.5.0)\n","Requirement already satisfied: widgetsnbextension~=3.5.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.5.1)\n","Requirement already satisfied: nbformat>=4.2.0 in /usr/local/lib/python3.6/dist-packages (from ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.0.8)\n","Requirement already satisfied: jupyter-client in /usr/local/lib/python3.6/dist-packages (from ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.5)\n","Requirement already satisfied: pygments in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (2.6.1)\n","Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.1)\n","Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.8.0)\n","Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.0.18)\n","Requirement already satisfied: pickleshare in /usr/local/lib/python3.6/dist-packages (from ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.7.5)\n","Requirement already satisfied: notebook>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.3.1)\n","Requirement already satisfied: jupyter-core in /usr/local/lib/python3.6/dist-packages (from nbformat>=4.2.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (4.6.3)\n","Requirement already satisfied: pyzmq>=13 in /usr/local/lib/python3.6/dist-packages (from jupyter-client->ipykernel>=5.1.2; python_version >= \"3.4\"->pydeck>=0.1.dev5->streamlit->simpletransformers) (19.0.2)\n","Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.6/dist-packages (from pexpect; sys_platform != \"win32\"->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n","Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython>=4.0.0; python_version >= \"3.3\"->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.2.5)\n","Requirement already satisfied: nbconvert in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (5.6.1)\n","Requirement already satisfied: Send2Trash in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.5.0)\n","Requirement already satisfied: terminado>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.9.1)\n","Requirement already satisfied: testpath in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.4.4)\n","Requirement already satisfied: bleach in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (3.2.1)\n","Requirement already satisfied: defusedxml in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.6.0)\n","Requirement already satisfied: pandocfilters>=1.4.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (1.4.3)\n","Requirement already satisfied: mistune<2,>=0.8.1 in /usr/local/lib/python3.6/dist-packages (from nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.8.4)\n","Requirement already satisfied: webencodings in /usr/local/lib/python3.6/dist-packages (from bleach->nbconvert->notebook>=4.4.1->widgetsnbextension~=3.5.0->ipywidgets>=7.0.0->pydeck>=0.1.dev5->streamlit->simpletransformers) (0.5.1)\n","Building wheels for collected packages: seqeval, subprocess32, watchdog, blinker, pathtools\n","  Building wheel for seqeval (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for seqeval: filename=seqeval-1.2.2-cp36-none-any.whl size=16171 sha256=20e29a0017abb46014209d7a6ac147c1cf21c08a01d810b9a9c6eb572ac5ae52\n","  Stored in directory: /root/.cache/pip/wheels/52/df/1b/45d75646c37428f7e626214704a0e35bd3cfc32eda37e59e5f\n","  Building wheel for subprocess32 (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for subprocess32: filename=subprocess32-3.5.4-cp36-none-any.whl size=6489 sha256=95b7528fbd33874b56ed06f64bae9b7d2a4973ba1f7087d1d52b4b64ff361200\n","  Stored in directory: /root/.cache/pip/wheels/68/39/1a/5e402bdfdf004af1786c8b853fd92f8c4a04f22aad179654d1\n","  Building wheel for watchdog (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for watchdog: filename=watchdog-0.10.3-cp36-none-any.whl size=73873 sha256=c1de465123b7720956de5b472d3c967b7e00ad81be648c3ce768218c1fa43f2f\n","  Stored in directory: /root/.cache/pip/wheels/a8/1d/38/2c19bb311f67cc7b4d07a2ec5ea36ab1a0a0ea50db994a5bc7\n","  Building wheel for blinker (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for blinker: filename=blinker-1.4-cp36-none-any.whl size=13450 sha256=935e187c5eb868a13379ce7f638fc723364d8ae8f5c96b531f58c57df28ec55d\n","  Stored in directory: /root/.cache/pip/wheels/92/a0/00/8690a57883956a301d91cf4ec999cc0b258b01e3f548f86e89\n","  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for pathtools: filename=pathtools-0.1.2-cp36-none-any.whl size=8785 sha256=a9e71814c988a7a4af5860b76f6f4f0ff4867bd540f13a40c7cf64f70da01fde\n","  Stored in directory: /root/.cache/pip/wheels/0b/04/79/c3b0c3a0266a3cb4376da31e5bfe8bba0c489246968a68e843\n","Successfully built seqeval subprocess32 watchdog blinker pathtools\n","\u001b[31mERROR: google-colab 1.0.0 has requirement ipykernel~=4.10, but you'll have ipykernel 5.3.4 which is incompatible.\u001b[0m\n","\u001b[31mERROR: botocore 1.19.13 has requirement urllib3<1.26,>=1.25.4; python_version != \"3.4\", but you'll have urllib3 1.24.3 which is incompatible.\u001b[0m\n","Installing collected packages: subprocess32, smmap, gitdb, GitPython, sentry-sdk, pathtools, watchdog, shortuuid, configparser, docker-pycreds, wandb, seqeval, jmespath, botocore, s3transfer, boto3, enum-compat, validators, ipykernel, pydeck, blinker, base58, streamlit, tqdm, tensorboardx, simpletransformers\n","  Found existing installation: ipykernel 4.10.1\n","    Uninstalling ipykernel-4.10.1:\n","      Successfully uninstalled ipykernel-4.10.1\n","  Found existing installation: tqdm 4.41.1\n","    Uninstalling tqdm-4.41.1:\n","      Successfully uninstalled tqdm-4.41.1\n","Successfully installed GitPython-3.1.11 base58-2.0.1 blinker-1.4 boto3-1.16.13 botocore-1.19.13 configparser-5.0.1 docker-pycreds-0.4.0 enum-compat-0.0.3 gitdb-4.0.5 ipykernel-5.3.4 jmespath-0.10.0 pathtools-0.1.2 pydeck-0.5.0 s3transfer-0.3.3 sentry-sdk-0.19.2 seqeval-1.2.2 shortuuid-1.0.1 simpletransformers-0.48.15 smmap-3.0.4 streamlit-0.70.0 subprocess32-3.5.4 tensorboardx-2.1 tqdm-4.51.0 validators-0.18.1 wandb-0.10.9 watchdog-0.10.3\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.colab-display-data+json":{"pip_warning":{"packages":["ipykernel"]}}},"metadata":{"tags":[]}}]},{"cell_type":"code","metadata":{"id":"zsOIA6KXUdz_"},"source":["# pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsHo75fupasE"},"source":["import pandas as pd\n","import numpy as np\n","import os\n","# import src\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ePRqI5M3qPi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855677572,"user_tz":360,"elapsed":37931,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"fae7d5fa-3dc2-494f-c44e-ded6971a20af"},"source":["pip install -U mittens"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mittens\n","  Downloading https://files.pythonhosted.org/packages/ce/c0/6e4fce5b3cb88edde2e657bb4da9885c0aeac232981706beed7f43773b00/mittens-0.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from mittens) (1.18.5)\n","Installing collected packages: mittens\n","Successfully installed mittens-0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hgktrAVlpZdb"},"source":["from numpy import asarray\n","from numpy import zeros\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","\n","from statistics import mean, stdev, median, mode\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from mittens import GloVe, Mittens\n","from hyperopt import fmin, tpe, hp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8mtQwKZinpq"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.models import load_model\n","\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv3D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.layers import MaxPool3D, AveragePooling3D\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import AveragePooling3D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mDAc3bBinpt"},"source":["import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten, Dropout, MaxPool1D\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional\n","import tensorflow.keras.backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hUr_cPsUd0S"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.models import load_model\n","\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv3D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.layers import MaxPool3D, AveragePooling3D\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import AveragePooling3D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwmaSGo4qkCR"},"source":["from hyperopt import fmin, tpe, hp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NO6oNPy7px_h"},"source":["# pip install autocorrect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BALelbZyNU02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855685626,"user_tz":360,"elapsed":902,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"57bef7be-87f8-47ae-8c0b-cd19984ae6b0"},"source":["nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":20}]},{"cell_type":"code","metadata":{"id":"w8gGSNnE_Ngv"},"source":["import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten, Dropout, MaxPool1D\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional\n","import tensorflow.keras.backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WejUuvUHUd0f","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855691269,"user_tz":360,"elapsed":4612,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"039828bd-c116-46ba-f885-5c0635b66638"},"source":["from simpletransformers.classification import ClassificationModel, ClassificationArgs"],"execution_count":null,"outputs":[{"output_type":"stream","text":["\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m W&B installed but not logged in.  Run `wandb login` or set the WANDB_API_KEY env variable.\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"8nyt2ltYpZd5"},"source":["### Getting Data"]},{"cell_type":"code","metadata":{"id":"T9A1Zv-FUd0l"},"source":["# data_path = r'C:\\Users\\kalya\\OneDrive - University of Illinois at Chicago\\!UIC\\!Semesters\\3rd Sem\\CS 583 Data Mining and Text Mining\\Research Project\\Data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIfhW_B6Ud0q"},"source":["data_path = r'/content/drive/My Drive/Research Project/Data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUlxykQWUd04"},"source":["train1_pr_df = pd.read_csv(os.path.join(data_path, 'Combined Training1 Data.csv'), usecols = [1,2],names= ['text', 'labels'], header  = 0).dropna()\n","train1_pr_df['labels'] = train1_pr_df['labels'].apply(lambda x: 0 if x == 'Positive' else (2 if x == 'Negative' else 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEc3NWz2lTPf"},"source":["def evaluation(labels, preds):\n","\n","  f1_temp = np.round(f1_score(labels, preds, average=None),3)\n","\n","  f1_Positive = f1_temp[0]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[2]\n","  accuracy = round(accuracy_score(labels, preds),3) \n","  eval_score = round(mean([accuracy, f1_Positive, f1_Negative]),3) \n","  return eval_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACIKrVuXUd07","colab":{"base_uri":"https://localhost:8080/","height":204},"executionInfo":{"status":"ok","timestamp":1604855698558,"user_tz":360,"elapsed":213,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"030c8f7d-5cd1-471f-8fd7-cf0979d60afa"},"source":["train1_pr_df.head()"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>text</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>debate job come back obama get as make corp ta...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>romney romney abrasive</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>sicken obama war woman tom halloran</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>mitt romney business genius speculator play bi...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>day election day ready cheer president obama t...</td>\n","      <td>0</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["                                                text  labels\n","0  debate job come back obama get as make corp ta...       2\n","1                             romney romney abrasive       2\n","2                sicken obama war woman tom halloran       2\n","3  mitt romney business genius speculator play bi...       2\n","4  day election day ready cheer president obama t...       0"]},"metadata":{"tags":[]},"execution_count":30}]},{"cell_type":"markdown","metadata":{"id":"MoVlA_IAUd1C"},"source":["\n","## Transformer"]},{"cell_type":"code","metadata":{"id":"QSnOqcldrIAT"},"source":["def transformer_pred(train_pr_df, val_pr_df):\n","  max_length = 20\n","  batch_size = 32\n","\n","  print('Transformers')\n","  par_dict = {'max_length': max_length, 'batch_size': batch_size}\n","  print(par_dict)\n","  model_args = ClassificationArgs(num_train_epochs=2, train_batch_size = batch_size, overwrite_output_dir=True, max_seq_length = max_length)\n","  model = ClassificationModel(model_type='roberta', model_name='roberta-base', use_cuda=True, num_labels=3, args=model_args)\n","  model.train_model(train_pr_df)\n","\n","  y_pred_T = model.predict(val_pr_df['text'])[0]\n","  return y_pred_T"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JIU_zsIKinqN"},"source":["### CNN"]},{"cell_type":"code","metadata":{"id":"0c-nCJhQinqN"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Nt4Q-LLu_Nh6"},"source":["def one_hot(data):\n","    data = np.asarray(data)\n","    temp = np.zeros((len(data),3))\n","#     print(data[0])\n","    for i in range(len(temp)):\n","        if data[i] == 'Negative':\n","            temp[i][2] = 1 ## Negative sentiment third neuron\n","        elif data[i] == 'Neutral':\n","            temp[i][1] = 1 ## Neutral sentiment second neuron  \n","        else:\n","            temp[i][0] = 1 ## Positive sentiment first neuron \n","\n","    return temp\n","    \n","    \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"rvXTaKyi5ZNt"},"source":["def pred(x):\n","    temp = []\n","    for i in x:\n","        m = np.argmax(i)\n","        if m == 0:\n","            temp.append('Positive')\n","        elif m == 1:\n","            temp.append('Neutral')\n","        else:\n","            temp.append('Negative')\n","    return temp"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wmGshHslpZeH"},"source":["## Building Glove Dictionary"]},{"cell_type":"code","metadata":{"id":"YU-SxaOZ_Nh9"},"source":["embeddings = {}\n","with open(os.path.join(data_path,\"glove.twitter.27B.200d.txt\"), 'r', encoding=\"utf-8\") as file:\n","    for line in file:\n","        values = line.split()\n","        word = values[0]\n","        vector = asarray(values[1:], dtype='float32')\n","        embeddings[word] = vector"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"or3hmQvdpZeJ"},"source":["## Embedding Matrix Function"]},{"cell_type":"code","metadata":{"id":"wBG3Kq7EpZeJ"},"source":["def emb_matrix(t,embeddings, we_dim):\n","    # creating a embedding matrix for the words in training data, which will be used as weight matrix for embedding layer\n","    vocab_size = len(t.word_index) + 1    \n","    embedding_matrix = zeros((vocab_size, we_dim))\n","    for word, i in t.word_index.items():\n","        embedding_vector = embeddings.get(word)\n","        if embedding_vector is not None:\n","            embedding_matrix[i] = embedding_vector\n","    return embedding_matrix, vocab_size"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"9kT9ZAXi_NiC"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MgK6d3Qy_NiF"},"source":["## Fine tuning the word embeddings of 300 dimensions using mittens library\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VqwJmPT-_NiF"},"source":["## Used the code for finetuning from the following link:\n","### https://towardsdatascience.com/fine-tune-glove-embeddings-using-mittens-89b5f3fe4c39"]},{"cell_type":"code","metadata":{"id":"HRwhIKRT_NiF"},"source":["def finetune(training): \n","    training_tokens = [word_tokenize(i) for i in training['text']]\n","    #training_tokens\n","\n","    oov = [j for i in training_tokens for j in i if j not in embeddings.keys()]\n","    print(len(oov))\n","\n","    corp_vocab = list(set(oov))\n","\n","    cv = CountVectorizer(ngram_range=(1,1), vocabulary=corp_vocab)\n","    trr =''\n","    for i in training_tokens:\n","        for j in i:\n","            trr+= j\n","            trr += ' '\n","\n","    # print(trr)\n","    # print(z)\n","    X = cv.fit_transform([trr])\n","    Xc = (X.T * X)\n","    Xc.setdiag(0)\n","    coocc_ar = Xc.toarray()\n","\n","    mittens_model = Mittens(n=200, max_iter=len(oov)+200)\n","\n","    new_embeddings = mittens_model.fit(\n","      coocc_ar,\n","      vocab=corp_vocab,\n","      initial_embedding_dict= embeddings)\n","\n","    new_embeddings = dict(zip(corp_vocab, new_embeddings))\n","    return training_tokens, new_embeddings\n","  \n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"MB2Nd-Kr_NiH","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855965141,"user_tz":360,"elapsed":19517,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"a81f9b3b-b1b2-483b-ee01-094559593005"},"source":["embeddings2= embeddings.copy()\n","\n","training_tokens, new_embeddings = finetune(train_pr_df)\n","embeddings2.update(new_embeddings)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["1146\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/training/adagrad.py:77: calling Constant.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Call initializer instance with the dtype argument instead of passing it to the constructor\n"],"name":"stdout"},{"output_type":"stream","text":["Iteration 1340: loss: 0.033130258321762085"],"name":"stderr"}]},{"cell_type":"code","metadata":{"id":"spGvX_Cg_NiI","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1604855965142,"user_tz":360,"elapsed":8077,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"56a6b73b-a576-4288-db4f-c3a62857d596"},"source":["oov2 = [j for i in training_tokens for j in i if j not in embeddings2.keys()]\n","print(len(oov2))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"z1VC6aXYinqP"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ZQ_WOJe96xsa"},"source":["def model_cnn1(embedding_matrix, vocab_size, epochs,batch_size,max_length, learning_rate, we_dim):\n","\n","    adam_optimizer = optimizers.Adam(learning_rate=learning_rate)\n","\n","    embedding_layer = Embedding(vocab_size, we_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),trainable=False)\n","    int_sequences_input = layers.Input(shape=(None,), dtype=\"int64\")\n","    embedded_sequences = embedding_layer(int_sequences_input)\n","\n","    x = layers.Conv1D(64, 3)(embedded_sequences)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU()(x)\n","    x = layers.MaxPooling1D(2)(x)\n","    x = layers.Conv1D(128, 3)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU()(x)\n","    x = layers.MaxPooling1D(2)(x)\n","\n","    x = layers.Conv1D(256, 3)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU()(x)\n","    x = layers.GlobalMaxPooling1D()(x)\n","    # x = layers.MaxPooling1D(2)(x)\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(128, activation=\"tanh\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(128, activation=\"tanh\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    preds = layers.Dense(3, activation=\"softmax\")(x)\n","\n","    model = tf.keras.Model(int_sequences_input, preds)\n","    # print(model.summary())\n","    # print(z)\n","    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"0-q5ICwzkjY8"},"source":["def model_cnn2(embedding_matrix, vocab_size, epochs,batch_size,max_length, learning_rate, we_dim):\n","\n","    adam_optimizer = optimizers.Adam(learning_rate=learning_rate)\n","\n","    embedding_layer = Embedding(vocab_size, we_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),trainable=False)\n","    int_sequences_input = layers.Input(shape=(None,), dtype=\"int64\")\n","    embedded_sequences = embedding_layer(int_sequences_input)\n","\n","    x = layers.Conv1D(32, 3)(embedded_sequences)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU()(x)\n","    x = layers.MaxPooling1D(2)(x)\n","    x = layers.Conv1D(64, 3)(x)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU()(x)\n","    x = layers.GlobalMaxPooling1D()(x)\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(128, activation=\"tanh\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(128, activation=\"tanh\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    preds = layers.Dense(3, activation=\"softmax\")(x)\n","\n","    model = tf.keras.Model(int_sequences_input, preds)\n","    # print(model.summary())\n","    # print(z)\n","    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ixABj5x5kj33"},"source":["def model_cnn3(embedding_matrix, vocab_size, epochs,batch_size,max_length, learning_rate, we_dim):\n","\n","    adam_optimizer = optimizers.Adam(learning_rate=learning_rate)\n","\n","    embedding_layer = Embedding(vocab_size, we_dim, embeddings_initializer=tf.keras.initializers.Constant(embedding_matrix),trainable=False)\n","    int_sequences_input = layers.Input(shape=(None,), dtype=\"int64\")\n","    embedded_sequences = embedding_layer(int_sequences_input)\n","\n","    x = layers.Conv1D(64, 3)(embedded_sequences)\n","    x = BatchNormalization()(x)\n","    x = LeakyReLU()(x)\n","    x = layers.GlobalMaxPooling1D()(x)\n","\n","    x = layers.Flatten()(x)\n","    x = layers.Dense(128, activation=\"tanh\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    x = layers.Dense(128, activation=\"tanh\")(x)\n","    x = layers.Dropout(0.2)(x)\n","    preds = layers.Dense(3, activation=\"softmax\")(x)\n","\n","    model = tf.keras.Model(int_sequences_input, preds)\n","    # print(model.summary())\n","    # print(z)\n","    model.compile(optimizer=adam_optimizer, loss='categorical_crossentropy', metrics=['acc'])\n","    return model\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"Br37hmEPjBe5"},"source":["def cnn_pred (train_pr_df, val_pr_df): \n","  we_dim = 200   \n","  max_length = 48\n","  batch_size = 64\n","  learning_rate = 0.007428450405689178\n","  epochs = 7\n","\n","  print('CNN')\n","  par_dict = {'max_length': max_length, 'batch_size': batch_size, 'learning_rate': learning_rate, 'epochs': epochs}\n","  print(par_dict)\n","\n","  tokenise_tf = Tokenizer()\n","  tokenise_tf.fit_on_texts(train_pr_df['text']) \n","\n","  train_labels_temp = train_pr_df['labels'].apply(lambda x: 'Positive' if x == 0 else ('Negative' if x == 2 else 'Neutral'))\n","  val_labels_temp = val_pr_df['labels'].apply(lambda x: 'Positive' if x == 0 else ('Negative' if x == 2 else 'Neutral'))\n","\n","  encoded_train = tokenise_tf.texts_to_sequences(train_pr_df['text'])\n","  training_padded = pad_sequences(encoded_train, maxlen=max_length, padding='post', truncating = 'pre')\n","  embedding_matrix, vocab_size = emb_matrix(tokenise_tf, embeddings, we_dim)\n","\n","  encoded_validation = tokenise_tf.texts_to_sequences(val_pr_df['text'])\n","  validation_padded = pad_sequences(encoded_validation, maxlen=max_length, padding='post', truncating = 'pre')\n","\n","  try: \n","      model = model_cnn1(embedding_matrix, vocab_size, epochs,batch_size,max_length, learning_rate, we_dim)\n","      history = model.fit(training_padded, one_hot(train_labels_temp), epochs=epochs, verbose=0, batch_size=batch_size, shuffle =True)\n","\n","  except:\n","      try:            \n","          model = model_cnn2(embedding_matrix, vocab_size, epochs,batch_size,max_length, learning_rate, we_dim)\n","          history = model.fit(training_padded, one_hot(train_labels_temp), epochs=epochs, verbose=0, batch_size=batch_size, shuffle =True)\n","      except:\n","\n","          model = model_cnn3(embedding_matrix, vocab_size, epochs,batch_size,max_length, learning_rate, we_dim)\n","          history = model.fit(training_padded, one_hot(train_labels_temp), epochs=epochs, verbose=0, batch_size=batch_size, shuffle =True)\n","\n","\n","  y_pred_temp = model.predict(validation_padded)\n","  y_pred = pred(y_pred_temp)\n","  f1_temp = np.round(f1_score(val_labels_temp, y_pred, average = None),3)\n","\n","  f1_Positive = f1_temp[2]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[0]\n","\n","  accuracy = round(accuracy_score(val_labels_temp, y_pred),3) \n","  eval_score = round(mean([0.4*accuracy, 1.6*f1_Positive]),3)   \n","  eval_dict = {'accuracy': accuracy, 'f1_pos': f1_Positive, 'f1_neu': f1_Neutral, 'f1_neg': f1_Negative, 'eval_score': eval_score}\n","  print('\\n')\n","  print(eval_dict)\n","  print(dsdsdfg)\n","  return temp\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vy0Z1e1IkWBL","colab":{"base_uri":"https://localhost:8080/","height":367},"executionInfo":{"status":"error","timestamp":1604857481451,"user_tz":360,"elapsed":15193,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"b97445fa-105c-4b01-f1ee-c1a388108d0c"},"source":["y_pred_cnn = cnn_pred (train_pr_df, val_pr_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["CNN\n","{'max_length': 48, 'batch_size': 64, 'learning_rate': 0.007428450405689178, 'epochs': 7}\n","\n","\n","{'accuracy': 0.538, 'f1_pos': 0.491, 'f1_neu': 0.467, 'f1_neg': 0.62, 'eval_score': 0.5}\n"],"name":"stdout"},{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-78-015f34930ceb>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_pred_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_pred\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_pr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-76-449aab16bac0>\u001b[0m in \u001b[0;36mcnn_pred\u001b[0;34m(train_pr_df, val_pr_df)\u001b[0m\n\u001b[1;32m     50\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0meval_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdsdsdfg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     53\u001b[0m   \u001b[0;32mreturn\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dsdsdfg' is not defined"]}]},{"cell_type":"code","metadata":{"id":"BTVMYzjwkWD2"},"source":["def ensemble(train_pr_df, val_pr_df):\n","  y_pred_T = transformer_pred(train_pr_df, val_pr_df)\n","  y_pred_cnn = cnn_pred (train_pr_df, val_pr_df)\n","  temp = (1.2*y_pred_T + 0.8*y_pred_cnn)/2\n","  y_pred = [1 if i >= 0.5 else 0 for i in temp]\n","  f1_temp = np.round(f1_score(val_pr_df['labels'], y_pred, average = None),3)\n","\n","  f1_Positive = f1_temp[0]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[2]\n","\n","  accuracy = round(accuracy_score(val_pr_df['labels'], y_pred),3) \n","  eval_score = round(mean([0.4*accuracy, 1.6*f1_Positive]),3)   \n","  eval_dict = {'accuracy': accuracy, 'f1_pos': f1_Positive, 'f1_neu': f1_Neutral, 'f1_neg': f1_Negative, 'eval_score': eval_score}\n","  print('\\n')\n","  print(eval_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i67tuwnD3u5O","colab":{"base_uri":"https://localhost:8080/","height":340},"executionInfo":{"status":"error","timestamp":1604856516233,"user_tz":360,"elapsed":7982,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"d75ecb0f-a5b7-4b76-804f-0cefddf0c12b"},"source":["ensemble(train_pr_df, val_pr_df)"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Transformers\n","{'max_length': 20, 'batch_size': 32}\n"],"name":"stdout"},{"output_type":"error","ename":"KeyboardInterrupt","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m<ipython-input-54-1afcc7af99f0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m<ipython-input-53-66d170d2ef18>\u001b[0m in \u001b[0;36mensemble\u001b[0;34m(train_pr_df, val_pr_df)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m   \u001b[0my_pred_T\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtransformer_pred\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m   \u001b[0my_pred_cnn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcnn_pred\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mtrain_pr_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_pr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0mtemp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1.2\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my_pred_T\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m0.8\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0my_pred_cnn\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m/\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m   \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mi\u001b[0m \u001b[0;34m>=\u001b[0m \u001b[0;36m0.5\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtemp\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-47-335b81f57708>\u001b[0m in \u001b[0;36mtransformer_pred\u001b[0;34m(train_pr_df, val_pr_df)\u001b[0m\n\u001b[1;32m      7\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpar_dict\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mmodel_args\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationArgs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_train_epochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_batch_size\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moverwrite_output_dir\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmax_seq_length\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax_length\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 9\u001b[0;31m   \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roberta'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmodel_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'roberta-base'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muse_cuda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     10\u001b[0m   \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_pr_df\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, model_type, model_name, num_labels, weight, args, use_cuda, cuda_device, onnx_execution_provider, **kwargs)\u001b[0m\n\u001b[1;32m    221\u001b[0m                     )\n\u001b[1;32m    222\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_class\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m                 \u001b[0mquantized_weights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"pytorch_model.bin\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/transformers/modeling_utils.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    949\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mstate_dict\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mfrom_tf\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    950\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 951\u001b[0;31m                 \u001b[0mstate_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresolved_archive_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"cpu\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    952\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    953\u001b[0m                 raise OSError(\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    593\u001b[0m                     \u001b[0;32mreturn\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjit\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    594\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0m_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_zipfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 595\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_legacy_load\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopened_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpickle_module\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mpickle_load_args\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    596\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/torch/serialization.py\u001b[0m in \u001b[0;36m_legacy_load\u001b[0;34m(f, map_location, pickle_module, **pickle_load_args)\u001b[0m\n\u001b[1;32m    779\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_storage_keys\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    780\u001b[0m         \u001b[0;32massert\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 781\u001b[0;31m         \u001b[0mdeserialized_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_set_from_file\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moffset\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mf_should_read_directly\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    782\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moffset\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    783\u001b[0m             \u001b[0moffset\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtell\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mKeyboardInterrupt\u001b[0m: "]}]},{"cell_type":"code","metadata":{"id":"sccZXVZy39s_"},"source":[""],"execution_count":null,"outputs":[]}]}