{"nbformat":4,"nbformat_minor":0,"metadata":{"accelerator":"GPU","colab":{"name":"Romney_Twitter_Sentiment_Analysis_Ensemble.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.8.3"}},"cells":[{"cell_type":"code","metadata":{"id":"78PhOL0jpZdY","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606785932454,"user_tz":360,"elapsed":13479,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"507ec405-651a-41f3-e212-f1769e60521c"},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Mounted at /content/drive\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"AEM1ZS6vpu6b","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606785932455,"user_tz":360,"elapsed":13472,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"6ddbaa37-aab2-40d0-d0b0-0f7fc3606015"},"source":["%cd /content/drive/My Drive/Research Project"],"execution_count":null,"outputs":[{"output_type":"stream","text":["/content/drive/My Drive/Research Project\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h0jpgwEQU_Av"},"source":["# pip install --upgrade transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"jvEqRZL_Udz7","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606786732916,"user_tz":360,"elapsed":4811,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"06ce516b-023f-40a3-c5c3-ff7022db92d3"},"source":["pip uninstall transformers"],"execution_count":19,"outputs":[{"output_type":"stream","text":["Uninstalling transformers-4.0.0:\n","  Would remove:\n","    /usr/local/bin/transformers-cli\n","    /usr/local/lib/python3.6/dist-packages/transformers-4.0.0.dist-info/*\n","    /usr/local/lib/python3.6/dist-packages/transformers/*\n","Proceed (y/n)? y\n","  Successfully uninstalled transformers-4.0.0\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"zsOIA6KXUdz_"},"source":["# pip install transformers"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QsHo75fupasE"},"source":["import pandas as pd\n","import numpy as np\n","import os\n","# import src\n","import matplotlib.pyplot as plt\n","import seaborn as sns"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"4ePRqI5M3qPi","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606785961879,"user_tz":360,"elapsed":42878,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"8370b745-4cc0-4c34-ca54-10e6389f7cdf"},"source":["pip install -U mittens"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Collecting mittens\n","  Downloading https://files.pythonhosted.org/packages/ce/c0/6e4fce5b3cb88edde2e657bb4da9885c0aeac232981706beed7f43773b00/mittens-0.2-py3-none-any.whl\n","Requirement already satisfied, skipping upgrade: numpy in /usr/local/lib/python3.6/dist-packages (from mittens) (1.18.5)\n","Installing collected packages: mittens\n","Successfully installed mittens-0.2\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"hgktrAVlpZdb"},"source":["from numpy import asarray\n","from numpy import zeros\n","\n","from sklearn.utils import shuffle\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","\n","from statistics import mean, stdev, median, mode\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","from mittens import GloVe, Mittens\n","from hyperopt import fmin, tpe, hp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EC3ptj56ONJI"},"source":["from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n","from sklearn.feature_extraction.text import TfidfVectorizer\n","from sklearn.model_selection import train_test_split, cross_val_score, KFold\n","from statistics import mean, stdev, median, mode\n","# With PCA\n","from sklearn.decomposition import PCA\n","\n","from sklearn.feature_extraction.text import CountVectorizer\n","\n","#LR\n","from sklearn.linear_model import LogisticRegression\n","\n","# SVM\n","from sklearn.svm import SVC\n","from sklearn.naive_bayes import GaussianNB\n","# KNN\n","from sklearn.neighbors import KNeighborsClassifier\n","from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n","\n","from mittens import GloVe, Mittens"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"g8mtQwKZinpq"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.models import load_model\n","\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv3D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.layers import MaxPool3D, AveragePooling3D\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import AveragePooling3D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3mDAc3bBinpt"},"source":["import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten, Dropout, MaxPool1D\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional\n","import tensorflow.keras.backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"3hUr_cPsUd0S"},"source":["import tensorflow as tf\n","\n","from tensorflow.keras import Sequential\n","from tensorflow.keras.models import load_model\n","\n","from tensorflow.keras.layers import Embedding\n","from tensorflow.keras import layers\n","\n","from tensorflow.keras.layers import Input\n","from tensorflow.keras.layers import Conv3D\n","from tensorflow.keras.layers import BatchNormalization\n","from tensorflow.keras.layers import LeakyReLU\n","from tensorflow.keras.layers import PReLU\n","from tensorflow.keras.layers import MaxPool3D, AveragePooling3D\n","\n","from tensorflow.keras.layers import Dropout\n","from tensorflow.keras.layers import AveragePooling3D\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hwmaSGo4qkCR"},"source":["from hyperopt import fmin, tpe, hp"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NO6oNPy7px_h"},"source":["# pip install autocorrect"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BALelbZyNU02","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1606785965207,"user_tz":360,"elapsed":46189,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"a32351ac-e38c-4101-b37a-22e7a11ae7d3"},"source":["nltk.download('punkt')"],"execution_count":null,"outputs":[{"output_type":"stream","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt.zip.\n"],"name":"stdout"},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"w8gGSNnE_Ngv"},"source":["import tensorflow_addons as tfa\n","from tensorflow.keras.preprocessing.text import Tokenizer\n","from tensorflow.keras.preprocessing.sequence import pad_sequences\n","from tensorflow.keras.models import Sequential\n","from tensorflow.keras.layers import Dense\n","from tensorflow.keras.layers import Flatten, Dropout, MaxPool1D\n","from tensorflow.keras import optimizers\n","from tensorflow.keras.layers import Embedding, SimpleRNN, LSTM, GRU, Bidirectional\n","import tensorflow.keras.backend as K"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"WejUuvUHUd0f","colab":{"base_uri":"https://localhost:8080/","height":442},"executionInfo":{"status":"error","timestamp":1606785968641,"user_tz":360,"elapsed":49616,"user":{"displayName":"Kalyan Kumar Paladugula","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GhBypR7Wk5RJqa7mv464W6F2Ab5FPdsDmSKVqfY=s64","userId":"13683835722741163781"}},"outputId":"35553812-e1bd-43e9-da78-8458c36a5b65"},"source":["from simpletransformers.classification import ClassificationModel, ClassificationArgs"],"execution_count":null,"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-17-29f08e6c2d87>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mClassificationArgs\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mClassificationModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_label_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiLabelClassificationModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmulti_modal_classification_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMultiModalClassificationModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m from simpletransformers.config.model_args import (\n\u001b[1;32m      5\u001b[0m     \u001b[0mClassificationArgs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/classification_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     72\u001b[0m     \u001b[0mconvert_examples_to_features\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m )\n\u001b[0;32m---> 74\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0malbert_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlbertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbert_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msimpletransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtransformer_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcamembert_model\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCamembertForSequenceClassification\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.6/dist-packages/simpletransformers/classification/transformer_models/albert_model.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnn\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnn\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mCrossEntropyLoss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMSELoss\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mtransformers\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodeling_albert\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mAlbertConfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertModel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mAlbertPreTrainedModel\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'transformers.modeling_albert'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"]}]},{"cell_type":"markdown","metadata":{"id":"8nyt2ltYpZd5"},"source":["### Getting Data"]},{"cell_type":"code","metadata":{"id":"T9A1Zv-FUd0l"},"source":["# data_path = r'C:\\Users\\kalya\\OneDrive - University of Illinois at Chicago\\!UIC\\!Semesters\\3rd Sem\\CS 583 Data Mining and Text Mining\\Research Project\\Data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"UIfhW_B6Ud0q"},"source":["data_path = r'/content/drive/My Drive/Research Project/Data'"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"oNHXXf7GUd0u"},"source":["train_pr_df = pd.read_csv(os.path.join(data_path, 'Romney Training Data.csv'), usecols = [1,2], names= ['text', 'labels'], header  = 0).dropna()\n","train_pr_df['labels'] = train_pr_df['labels'].apply(lambda x: 0 if x == 'Positive' else (2 if x == 'Negative' else 1))\n","val_pr_df = pd.read_csv(os.path.join(data_path, 'Romney Validation Data.csv'), usecols = [1,2], names= ['text', 'labels'], header  = 0).dropna()\n","val_pr_df['labels'] = val_pr_df['labels'].apply(lambda x: 0 if x == 'Positive' else (2 if x == 'Negative' else 1))"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"AD9U00CVddNC"},"source":["train_pr_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gUfXehsEUd00"},"source":["val_pr_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"8p0sdWWNQSqf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"XUlxykQWUd04"},"source":["train1_pr_df = pd.read_csv(os.path.join(data_path, 'Romney Training1 Data.csv'), usecols = [1,2],names= ['text', 'labels'], header  = 0).dropna()\n","train1_pr_df['labels'] = train1_pr_df['labels'].apply(lambda x: 0 if x == 'Positive' else (2 if x == 'Negative' else 1))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"ILQXZJP8LKmr"},"source":["### Converting into TF-IDF"]},{"cell_type":"code","metadata":{"id":"mXJwrtOtaCiQ"},"source":["def tf_idf(x):\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform(x)\n","    #print(tfidf_matrix)\n","    x1 = tfidf_matrix.toarray()\n","#     print(x1)\n","    return x1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"04diRcvqT4s8"},"source":["def tf_idf2(x):\n","    vectorizer = TfidfVectorizer()\n","    tfidf_matrix = vectorizer.fit_transform(x)\n","    #print(tfidf_matrix)\n","    x1 = tfidf_matrix.toarray()\n","#     print(x1)\n","    return x1"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"mFoRZ3E3RHaS"},"source":["\n","vectorizer = TfidfVectorizer()\n","tfidf_matrix = vectorizer.fit_transform(train_pr_df['text'])\n","#print(tfidf_matrix)\n","train_pr_tfidf = tfidf_matrix.toarray()\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"b7Am3LulRQqm"},"source":["train_pr_tfidf.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gGj4fIxoRcQk"},"source":["\n","tfidf_matrix2 = vectorizer.transform(val_pr_df['text'])\n","#print(tfidf_matrix)\n","val_pr_tfidf = tfidf_matrix2.toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"z07Cups5RcQk"},"source":["val_pr_tfidf.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"hM-Q2KTBaCiU"},"source":["vectorizer = TfidfVectorizer()\n","tfidf_matrix3 = vectorizer.fit_transform(train1_pr_df['text'])\n","#print(tfidf_matrix)\n","train1_pr_tfidf = tfidf_matrix3.toarray()"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"NimCgs87eUzF"},"source":["train1_pr_tfidf.shape"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"gEc3NWz2lTPf"},"source":["def evaluation(labels, preds):\n","\n","  f1_temp = np.round(f1_score(labels, preds, average=None),3)\n","\n","  f1_Positive = f1_temp[0]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[2]\n","  accuracy = round(accuracy_score(labels, preds),3) \n","  eval_score = round(mean([accuracy, f1_Positive, f1_Negative]),3) \n","  return eval_score"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ACIKrVuXUd07"},"source":["train1_pr_df.head()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"MoVlA_IAUd1C"},"source":["\n","## Transformer"]},{"cell_type":"code","metadata":{"id":"0X56CAF1Jflu"},"source":["{'max_length': 55, 'batch_size': 16}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"QSnOqcldrIAT"},"source":["def transformer_pred(train_pr_df, test_pr_df,max_seq_length, train_batch_size):\n","  # max_length = 20\n","  # batch_size = 32\n","\n","  print('Transformers')\n","  par_dict = {'max_length': max_length, 'batch_size': batch_size}\n","  print(par_dict)\n","  model_args = ClassificationArgs(num_train_epochs=2, train_batch_size = train_batch_size, overwrite_output_dir=True, max_seq_length = max_seq_length)\n","  model = ClassificationModel(model_type='roberta', model_name='cardiffnlp/twitter-roberta-base-sentiment', use_cuda=True, num_labels=3, args=model_args)\n","  model.train_model(train_pr_df)\n","\n","  y_pred_T = model.predict(test_pr_df['text'])[0]\n","  return y_pred_T"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"vzaJI87XKG3s"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"cxjiWCtvKHbr"},"source":["### Logistic Regression"]},{"cell_type":"code","metadata":{"id":"rc_zGI5GKG8C"},"source":["{'C': 0.8}"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"p0mSjvrsKgMK"},"source":["def LR_pred(train_pr_tfidf, train_pr_df, test_pr_tfdf, C):\n","\n","  print('Logistic Regression')\n","  par_dict = {'C': C}\n","  print(par_dict)\n","  clf = LogisticRegression(C= C,class_weight='balanced',n_jobs =-1)\n","  clf.fit(train_pr_tfidf,train_pr_df['labels'])\n","  y_pred_LR = clf.predict(test_pr_tfdf)\n","  return y_pred_LR"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zcblpaAcKM3y"},"source":["## Ensemble"]},{"cell_type":"code","metadata":{"id":"ePHH_ka0Jecm"},"source":["max_length = 35\n","batch_size = 16\n","C = 0.51"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"BTVMYzjwkWD2"},"source":["def ensemble(train_pr_df, train_pr_tfidf, test_pr_df, test_pr_tfidf, max_length, batch_size, C):\n","  y_pred_T = transformer_pred(train_pr_df, test_pr_df,max_length, batch_size)\n","  y_pred_LR = LR_pred(train_pr_tfidf, train_pr_df, test_pr_tfidf, C)\n","  y_pred = np.round(0.7*y_pred_T + 0.3*y_pred_LR)\n","  f1_temp = np.round(f1_score(test_pr_df['labels'], y_pred, average = None),3)\n","\n","  f1_Positive = f1_temp[0]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[2]\n","\n","  accuracy = round(accuracy_score(test_pr_df['labels'], y_pred),3) \n","  eval_score = round(mean([0.4*accuracy, 1.6*f1_Positive]),3)   \n","  eval_dict = {'accuracy': accuracy, 'f1_pos': f1_Positive, 'f1_neu': f1_Neutral, 'f1_neg': f1_Negative, 'eval_score': eval_score}\n","  print('\\n')\n","  print(eval_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"i67tuwnD3u5O"},"source":["ensemble(train_pr_df, train_pr_tfidf, val_pr_df, val_pr_tfidf, max_length, batch_size, C)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"sccZXVZy39s_"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"wZpLkeuOH1c1"},"source":["def ensemble2(train_pr_df, train_pr_tfidf, test_pr_df, test_pr_tfidf, max_length, batch_size, C):\n","  y_pred = transformer_pred(train_pr_df, test_pr_df,max_length, batch_size)\n","  # y_pred_LR = LR_pred(train_pr_tfidf, train_pr_df, test_pr_tfidf, C)\n","  # y_pred = np.round(0.7*y_pred_T + 0.3*y_pred_LR)\n","  f1_temp = np.round(f1_score(test_pr_df['labels'], y_pred, average = None),3)\n","\n","  f1_Positive = f1_temp[0]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[2]\n","\n","  accuracy = round(accuracy_score(test_pr_df['labels'], y_pred),3) \n","  eval_score = round(mean([0.4*accuracy, 1.6*f1_Positive]),3)   \n","  eval_dict = {'accuracy': accuracy, 'f1_pos': f1_Positive, 'f1_neu': f1_Neutral, 'f1_neg': f1_Negative, 'eval_score': eval_score}\n","  print('\\n')\n","  print(eval_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"EqmMFyvoH1c1"},"source":["ensemble2(train_pr_df, train_pr_tfidf, val_pr_df, val_pr_tfidf, max_length, batch_size, C)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"dWLI33dbRan7"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LCCABMkXIwNf"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5SDmdqOIIwlp"},"source":["def ensemble3(train_pr_df, train_pr_tfidf, test_pr_df, test_pr_tfidf, max_length, batch_size, C):\n","  # y_pred = transformer_pred(train_pr_df, test_pr_df,max_length, batch_size)\n","  y_pred = LR_pred(train_pr_tfidf, train_pr_df, test_pr_tfidf, C)\n","  # y_pred = np.round(0.7*y_pred_T + 0.3*y_pred_LR)\n","  f1_temp = np.round(f1_score(test_pr_df['labels'], y_pred, average = None),3)\n","\n","  f1_Positive = f1_temp[0]\n","  f1_Neutral = f1_temp[1]\n","  f1_Negative = f1_temp[2]\n","\n","  accuracy = round(accuracy_score(test_pr_df['labels'], y_pred),3) \n","  eval_score = round(mean([0.4*accuracy, 1.6*f1_Positive]),3)   \n","  eval_dict = {'accuracy': accuracy, 'f1_pos': f1_Positive, 'f1_neu': f1_Neutral, 'f1_neg': f1_Negative, 'eval_score': eval_score}\n","  print('\\n')\n","  print(eval_dict)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"LC4byE4nIwlq"},"source":["ensemble3(train_pr_df, train_pr_tfidf, val_pr_df, val_pr_tfidf, max_length, batch_size, C)"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"chSAkwgYI1zb"},"source":[""],"execution_count":null,"outputs":[]}]}